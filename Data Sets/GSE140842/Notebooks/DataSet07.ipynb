{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Count</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>Accuracy_Test_Set</th>\n",
       "      <th>Cross_Val_Scores</th>\n",
       "      <th>Mean_Cross_Val_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.5, 0.6363636363636364, 0.6363636363636364, ...</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>[0.5833333333333334, 0.5454545454545454, 0.636...</td>\n",
       "      <td>0.571212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>[0.3333333333333333, 0.6363636363636364, 0.727...</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>[0.4166666666666667, 0.8181818181818182, 0.545...</td>\n",
       "      <td>0.556061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.3333333333333333, 0.36363636363636365, 0.45...</td>\n",
       "      <td>0.448485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>[0.5, 0.36363636363636365, 0.5454545454545454,...</td>\n",
       "      <td>0.481818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.7272727272727273, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>150</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.6363636363636364, ...</td>\n",
       "      <td>0.481818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>175</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>[0.75, 0.6363636363636364, 0.6363636363636364,...</td>\n",
       "      <td>0.677273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>175</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>175</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>[0.8333333333333334, 0.6363636363636364, 0.727...</td>\n",
       "      <td>0.693939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>180</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>[0.6666666666666666, 0.45454545454545453, 0.63...</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>180</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>[0.6666666666666666, 0.5454545454545454, 0.545...</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.7272727272727273, ...</td>\n",
       "      <td>0.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.5454545454545454, ...</td>\n",
       "      <td>0.536364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200</td>\n",
       "      <td>poly</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5, 0.6363636363636364, 0.7272727272727273, ...</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_Count  Kernel  Accuracy_Test_Set  \\\n",
       "0              25  linear           0.571429   \n",
       "1              25     rbf           0.357143   \n",
       "2              25    poly           0.428571   \n",
       "3              50  linear           0.785714   \n",
       "4              50     rbf           0.357143   \n",
       "5              50    poly           0.785714   \n",
       "6             100  linear           0.571429   \n",
       "7             100     rbf           0.357143   \n",
       "8             100    poly           0.428571   \n",
       "9             150  linear           0.571429   \n",
       "10            150     rbf           0.357143   \n",
       "11            150    poly           0.714286   \n",
       "12            175  linear           0.785714   \n",
       "13            175     rbf           0.357143   \n",
       "14            175    poly           0.857143   \n",
       "15            180  linear           0.857143   \n",
       "16            180     rbf           0.357143   \n",
       "17            180    poly           0.857143   \n",
       "18            200  linear           0.642857   \n",
       "19            200     rbf           0.357143   \n",
       "20            200    poly           0.642857   \n",
       "\n",
       "                                     Cross_Val_Scores  Mean_Cross_Val_Score  \n",
       "0   [0.5, 0.6363636363636364, 0.6363636363636364, ...              0.590909  \n",
       "1   [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "2   [0.5833333333333334, 0.5454545454545454, 0.636...              0.571212  \n",
       "3   [0.3333333333333333, 0.6363636363636364, 0.727...              0.575758  \n",
       "4   [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "5   [0.4166666666666667, 0.8181818181818182, 0.545...              0.556061  \n",
       "6   [0.3333333333333333, 0.36363636363636365, 0.45...              0.448485  \n",
       "7   [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "8   [0.5, 0.36363636363636365, 0.5454545454545454,...              0.481818  \n",
       "9   [0.5, 0.5454545454545454, 0.7272727272727273, ...              0.536364  \n",
       "10  [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "11  [0.5, 0.5454545454545454, 0.6363636363636364, ...              0.481818  \n",
       "12  [0.75, 0.6363636363636364, 0.6363636363636364,...              0.677273  \n",
       "13  [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "14  [0.8333333333333334, 0.6363636363636364, 0.727...              0.693939  \n",
       "15  [0.6666666666666666, 0.45454545454545453, 0.63...              0.515152  \n",
       "16  [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "17  [0.6666666666666666, 0.5454545454545454, 0.545...              0.515152  \n",
       "18  [0.5, 0.5454545454545454, 0.7272727272727273, ...              0.554545  \n",
       "19  [0.5, 0.5454545454545454, 0.5454545454545454, ...              0.536364  \n",
       "20  [0.5, 0.6363636363636364, 0.7272727272727273, ...              0.590909  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# List of feature counts for datasets\n",
    "feature_counts = [25, 50, 100, 150,175,180, 200]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for count in feature_counts:\n",
    "    # Load the dataset\n",
    "    file_path = f\"C:/Users/ACER/OneDrive - University of Jaffna/UOJ/Education/Research/Data Sets/GSE140842/Feature Selection/Information Gain/data_k_{count}.csv\"\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    X = df.drop('Diagnosis', axis=1)\n",
    "    y = df['Diagnosis']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # List of kernels to try\n",
    "    kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "    for kernel in kernels:\n",
    "        # Initialize an SVM model with the current kernel\n",
    "        svm_model = SVC(kernel=kernel)\n",
    "\n",
    "        # Train the SVM model on the training data\n",
    "        svm_model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the SVM model on the testing set\n",
    "        accuracy = svm_model.score(X_test, y_test)\n",
    "\n",
    "        # Perform k-fold cross-validation (e.g., 5-fold cross-validation)\n",
    "        cv_scores = cross_val_score(svm_model, X_train, y_train, cv=5)\n",
    "\n",
    "        # Store the results in a dictionary\n",
    "        result = {\n",
    "            'Feature_Count': count,\n",
    "            'Kernel': kernel,\n",
    "            'Accuracy_Test_Set': accuracy,\n",
    "            'Cross_Val_Scores': cv_scores,\n",
    "            'Mean_Cross_Val_Score': np.mean(cv_scores)\n",
    "        }\n",
    "\n",
    "        # Append the result to the list of results\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the final accuracy result table\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Count</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Test_Set</th>\n",
       "      <th>Cross_Val_Scores</th>\n",
       "      <th>Mean_Cross_Val_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.8333333333333334, 0.8181818181818182, 0.545...</td>\n",
       "      <td>0.693939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0.5, 0.8181818181818182, 0.6363636363636364, ...</td>\n",
       "      <td>0.627273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.6666666666666666, 0.5454545454545454, 0.818...</td>\n",
       "      <td>0.715152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.75, 0.8181818181818182, 0.7272727272727273,...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0.75, 0.6363636363636364, 0.7272727272727273,...</td>\n",
       "      <td>0.713636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.8333333333333334, 0.6363636363636364, 0.727...</td>\n",
       "      <td>0.730303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.75, 0.8181818181818182, 0.6363636363636364,...</td>\n",
       "      <td>0.731818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Count    Algorithm  Accuracy_Test_Set  \\\n",
       "0             25  Naive Bayes           0.571429   \n",
       "1             50  Naive Bayes           0.714286   \n",
       "2            100  Naive Bayes           0.571429   \n",
       "3            150  Naive Bayes           0.642857   \n",
       "4            175  Naive Bayes           0.714286   \n",
       "5            180  Naive Bayes           0.642857   \n",
       "6            200  Naive Bayes           0.571429   \n",
       "\n",
       "                                    Cross_Val_Scores  Mean_Cross_Val_Score  \n",
       "0  [0.8333333333333334, 0.8181818181818182, 0.545...              0.693939  \n",
       "1  [0.5, 0.8181818181818182, 0.6363636363636364, ...              0.627273  \n",
       "2  [0.6666666666666666, 0.5454545454545454, 0.818...              0.715152  \n",
       "3  [0.75, 0.8181818181818182, 0.7272727272727273,...              0.750000  \n",
       "4  [0.75, 0.6363636363636364, 0.7272727272727273,...              0.713636  \n",
       "5  [0.8333333333333334, 0.6363636363636364, 0.727...              0.730303  \n",
       "6  [0.75, 0.8181818181818182, 0.6363636363636364,...              0.731818  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB  # Import Gaussian Naive Bayes\n",
    "\n",
    "# List of feature counts for datasets\n",
    "feature_counts = [25, 50, 100, 150, 175, 180, 200]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for count in feature_counts:\n",
    "    # Load the dataset\n",
    "    file_path = f\"C:/Users/ACER/OneDrive - University of Jaffna/UOJ/Education/Research/Data Sets/GSE140842/Feature Selection/Information Gain/data_k_{count}.csv\"\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    X = df.drop('Diagnosis', axis=1)\n",
    "    y = df['Diagnosis']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # Initialize a Gaussian Naive Bayes model\n",
    "    nb_model = GaussianNB()\n",
    "\n",
    "    # Train the Naive Bayes model on the training data\n",
    "    nb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the Naive Bayes model on the testing set\n",
    "    accuracy = nb_model.score(X_test, y_test)\n",
    "\n",
    "    # Perform k-fold cross-validation (e.g., 5-fold cross-validation)\n",
    "    cv_scores = cross_val_score(nb_model, X_train, y_train, cv=5)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Feature_Count': count,\n",
    "        'Algorithm': 'Naive Bayes',  # Added to specify the algorithm used\n",
    "        'Accuracy_Test_Set': accuracy,\n",
    "        'Cross_Val_Scores': cv_scores,\n",
    "        'Mean_Cross_Val_Score': np.mean(cv_scores)\n",
    "    }\n",
    "\n",
    "    # Append the result to the list of results\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the final accuracy result table\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Count</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Test_Set</th>\n",
       "      <th>Cross_Val_Scores</th>\n",
       "      <th>Mean_Cross_Val_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>[0.5, 0.6363636363636364, 0.5454545454545454, ...</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>[0.3333333333333333, 0.6363636363636364, 0.636...</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0.4166666666666667, 0.5454545454545454, 0.454...</td>\n",
       "      <td>0.446970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>[0.5, 0.6363636363636364, 0.7272727272727273, ...</td>\n",
       "      <td>0.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.6666666666666666, 0.6363636363636364, 0.727...</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5833333333333334, 0.6363636363636364, 0.727...</td>\n",
       "      <td>0.571212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5, 0.8181818181818182, 0.6363636363636364, ...</td>\n",
       "      <td>0.554545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Count            Algorithm  Accuracy_Test_Set  \\\n",
       "0             25  Logistic Regression           0.500000   \n",
       "1             50  Logistic Regression           0.857143   \n",
       "2            100  Logistic Regression           0.714286   \n",
       "3            150  Logistic Regression           0.714286   \n",
       "4            175  Logistic Regression           0.642857   \n",
       "5            180  Logistic Regression           0.642857   \n",
       "6            200  Logistic Regression           0.642857   \n",
       "\n",
       "                                    Cross_Val_Scores  Mean_Cross_Val_Score  \n",
       "0  [0.5, 0.6363636363636364, 0.5454545454545454, ...              0.590909  \n",
       "1  [0.3333333333333333, 0.6363636363636364, 0.636...              0.575758  \n",
       "2  [0.4166666666666667, 0.5454545454545454, 0.454...              0.446970  \n",
       "3  [0.5, 0.6363636363636364, 0.7272727272727273, ...              0.554545  \n",
       "4  [0.6666666666666666, 0.6363636363636364, 0.727...              0.606061  \n",
       "5  [0.5833333333333334, 0.6363636363636364, 0.727...              0.571212  \n",
       "6  [0.5, 0.8181818181818182, 0.6363636363636364, ...              0.554545  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression  # Import Logistic Regression\n",
    "\n",
    "# List of feature counts for datasets\n",
    "feature_counts = [25, 50, 100, 150, 175, 180, 200]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for count in feature_counts:\n",
    "    # Load the dataset\n",
    "    file_path = f\"C:/Users/ACER/OneDrive - University of Jaffna/UOJ/Education/Research/Data Sets/GSE140842/Feature Selection/Information Gain/data_k_{count}.csv\"\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    X = df.drop('Diagnosis', axis=1)\n",
    "    y = df['Diagnosis']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # Initialize a Logistic Regression model\n",
    "    # Increase max_iter to 1000 or a higher value\n",
    "    lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Train the Logistic Regression model on the training data\n",
    "    lr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the Logistic Regression model on the testing set\n",
    "    accuracy = lr_model.score(X_test, y_test)\n",
    "\n",
    "    # Perform k-fold cross-validation (e.g., 5-fold cross-validation)\n",
    "    cv_scores = cross_val_score(lr_model, X_train, y_train, cv=5)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Feature_Count': count,\n",
    "        'Algorithm': 'Logistic Regression',  # Specify the algorithm used\n",
    "        'Accuracy_Test_Set': accuracy,\n",
    "        'Cross_Val_Scores': cv_scores,\n",
    "        'Mean_Cross_Val_Score': np.mean(cv_scores)\n",
    "    }\n",
    "\n",
    "    # Append the result to the list of results\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the final accuracy result table\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Count</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_Test_Set</th>\n",
       "      <th>Cross_Val_Scores</th>\n",
       "      <th>Mean_Cross_Val_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5833333333333334, 0.6363636363636364, 0.636...</td>\n",
       "      <td>0.571212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.4166666666666667, 0.8181818181818182, 0.727...</td>\n",
       "      <td>0.574242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5, 0.36363636363636365, 0.5454545454545454,...</td>\n",
       "      <td>0.427273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>[0.5, 0.5454545454545454, 0.8181818181818182, ...</td>\n",
       "      <td>0.554545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.5833333333333334, 0.7272727272727273, 0.454...</td>\n",
       "      <td>0.607576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[0.6666666666666666, 0.45454545454545453, 0.72...</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>[0.4166666666666667, 0.5454545454545454, 0.727...</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Count Algorithm  Accuracy_Test_Set  \\\n",
       "0             25       ANN           0.642857   \n",
       "1             50       ANN           0.571429   \n",
       "2            100       ANN           0.642857   \n",
       "3            150       ANN           0.428571   \n",
       "4            175       ANN           0.642857   \n",
       "5            180       ANN           0.571429   \n",
       "6            200       ANN           0.642857   \n",
       "\n",
       "                                    Cross_Val_Scores  Mean_Cross_Val_Score  \n",
       "0  [0.5833333333333334, 0.6363636363636364, 0.636...              0.571212  \n",
       "1  [0.4166666666666667, 0.8181818181818182, 0.727...              0.574242  \n",
       "2  [0.5, 0.36363636363636365, 0.5454545454545454,...              0.427273  \n",
       "3  [0.5, 0.5454545454545454, 0.8181818181818182, ...              0.554545  \n",
       "4  [0.5833333333333334, 0.7272727272727273, 0.454...              0.607576  \n",
       "5  [0.6666666666666666, 0.45454545454545453, 0.72...              0.515152  \n",
       "6  [0.4166666666666667, 0.5454545454545454, 0.727...              0.483333  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import MLPClassifier from scikit-learn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# List of feature counts for datasets\n",
    "feature_counts = [25, 50, 100, 150, 175, 180, 200]\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "for count in feature_counts:\n",
    "    # Load the dataset\n",
    "    file_path = f\"C:/Users/ACER/OneDrive - University of Jaffna/UOJ/Education/Research/Data Sets/GSE140842/Feature Selection/Information Gain/data_k_{count}.csv\"\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    X = df.drop('Diagnosis', axis=1)\n",
    "    y = df['Diagnosis']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # Standardize the features (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize an MLPClassifier (Artificial Neural Network)\n",
    "    ann_model = MLPClassifier(hidden_layer_sizes=(\n",
    "        100, 50), max_iter=1000, random_state=32)\n",
    "\n",
    "    # Train the ANN model on the training data\n",
    "    ann_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the ANN model on the testing set\n",
    "    accuracy = ann_model.score(X_test, y_test)\n",
    "\n",
    "    # Perform k-fold cross-validation (e.g., 5-fold cross-validation)\n",
    "    cv_scores = cross_val_score(ann_model, X_train, y_train, cv=5)\n",
    "\n",
    "    # Store the results in a dictionary\n",
    "    result = {\n",
    "        'Feature_Count': count,\n",
    "        'Algorithm': 'ANN',  # Specify the algorithm used\n",
    "        'Accuracy_Test_Set': accuracy,\n",
    "        'Cross_Val_Scores': cv_scores,\n",
    "        'Mean_Cross_Val_Score': np.mean(cv_scores)\n",
    "    }\n",
    "\n",
    "    # Append the result to the list of results\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the final accuracy result table\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Naive Bayes\n",
      "Best Feature Count: 50\n",
      "Best Accuracy: 0.7142857142857143\n",
      "\n",
      "Results DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature Count</th>\n",
       "      <th>Accuracy on Test Set</th>\n",
       "      <th>Mean Cross-Validation Score</th>\n",
       "      <th>Score Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANN</td>\n",
       "      <td>25</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.625758</td>\n",
       "      <td>-0.197186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ANN</td>\n",
       "      <td>50</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.537879</td>\n",
       "      <td>0.319264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ANN</td>\n",
       "      <td>100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>-0.054545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ANN</td>\n",
       "      <td>150</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.519697</td>\n",
       "      <td>0.194589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ANN</td>\n",
       "      <td>175</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.607576</td>\n",
       "      <td>0.106710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ANN</td>\n",
       "      <td>180</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.071861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ANN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.556061</td>\n",
       "      <td>0.015368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>25</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.465152</td>\n",
       "      <td>-0.036580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>50</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.334416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>100</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>-0.124675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>150</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>-0.106061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>175</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.624242</td>\n",
       "      <td>-0.052814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>180</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642424</td>\n",
       "      <td>0.071861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>200</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>25</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.693939</td>\n",
       "      <td>-0.122511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>50</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.087013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>-0.143723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>150</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-0.107143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>175</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.713636</td>\n",
       "      <td>0.000649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>180</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.730303</td>\n",
       "      <td>-0.087446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>200</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>-0.160390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>25</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.518182</td>\n",
       "      <td>-0.089610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>50</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.556061</td>\n",
       "      <td>0.229654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>100</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>-0.230952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVM</td>\n",
       "      <td>150</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>-0.036364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVM</td>\n",
       "      <td>175</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.677273</td>\n",
       "      <td>-0.105844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVM</td>\n",
       "      <td>180</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.589394</td>\n",
       "      <td>0.124892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVM</td>\n",
       "      <td>200</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.106494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Feature Count  Accuracy on Test Set  \\\n",
       "3                   ANN             25              0.428571   \n",
       "7                   ANN             50              0.857143   \n",
       "11                  ANN            100              0.500000   \n",
       "15                  ANN            150              0.714286   \n",
       "19                  ANN            175              0.714286   \n",
       "23                  ANN            180              0.714286   \n",
       "27                  ANN            200              0.571429   \n",
       "2   Logistic Regression             25              0.428571   \n",
       "6   Logistic Regression             50              0.857143   \n",
       "10  Logistic Regression            100              0.357143   \n",
       "14  Logistic Regression            150              0.500000   \n",
       "18  Logistic Regression            175              0.571429   \n",
       "22  Logistic Regression            180              0.714286   \n",
       "26  Logistic Regression            200              0.642857   \n",
       "1           Naive Bayes             25              0.571429   \n",
       "5           Naive Bayes             50              0.714286   \n",
       "9           Naive Bayes            100              0.571429   \n",
       "13          Naive Bayes            150              0.642857   \n",
       "17          Naive Bayes            175              0.714286   \n",
       "21          Naive Bayes            180              0.642857   \n",
       "25          Naive Bayes            200              0.571429   \n",
       "0                   SVM             25              0.428571   \n",
       "4                   SVM             50              0.785714   \n",
       "8                   SVM            100              0.285714   \n",
       "12                  SVM            150              0.500000   \n",
       "16                  SVM            175              0.571429   \n",
       "20                  SVM            180              0.714286   \n",
       "24                  SVM            200              0.642857   \n",
       "\n",
       "    Mean Cross-Validation Score  Score Difference  \n",
       "3                      0.625758         -0.197186  \n",
       "7                      0.537879          0.319264  \n",
       "11                     0.554545         -0.054545  \n",
       "15                     0.519697          0.194589  \n",
       "19                     0.607576          0.106710  \n",
       "23                     0.642424          0.071861  \n",
       "27                     0.556061          0.015368  \n",
       "2                      0.465152         -0.036580  \n",
       "6                      0.522727          0.334416  \n",
       "10                     0.481818         -0.124675  \n",
       "14                     0.606061         -0.106061  \n",
       "18                     0.624242         -0.052814  \n",
       "22                     0.642424          0.071861  \n",
       "26                     0.590909          0.051948  \n",
       "1                      0.693939         -0.122511  \n",
       "5                      0.627273          0.087013  \n",
       "9                      0.715152         -0.143723  \n",
       "13                     0.750000         -0.107143  \n",
       "17                     0.713636          0.000649  \n",
       "21                     0.730303         -0.087446  \n",
       "25                     0.731818         -0.160390  \n",
       "0                      0.518182         -0.089610  \n",
       "4                      0.556061          0.229654  \n",
       "8                      0.516667         -0.230952  \n",
       "12                     0.536364         -0.036364  \n",
       "16                     0.677273         -0.105844  \n",
       "20                     0.589394          0.124892  \n",
       "24                     0.536364          0.106494  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# List of feature counts for datasets\n",
    "feature_counts = [25, 50, 100, 150, 175, 180, 200]\n",
    "\n",
    "# List of models to compare\n",
    "models = {\n",
    "    'SVM': SVC(kernel='linear'),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'ANN': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000)\n",
    "}\n",
    "\n",
    "# Variables to track the best accuracy and model\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "best_feature_count = None\n",
    "\n",
    "# Threshold for identifying potential overfitting\n",
    "overfitting_threshold = 0.05  # You can adjust this threshold as needed\n",
    "\n",
    "# Lists to store results\n",
    "results = []\n",
    "\n",
    "for count in feature_counts:\n",
    "    # Load the dataset\n",
    "    file_path = f\"C:/Users/ACER/OneDrive - University of Jaffna/UOJ/Education/Research/Data Sets/GSE140842/Feature Selection/Information Gain/data_k_{count}.csv\"\n",
    "    df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "    X = df.drop('Diagnosis', axis=1)\n",
    "    y = df['Diagnosis']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "    # Standardize the features (important for some models)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model on the testing set\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "\n",
    "        # Perform k-fold cross-validation (e.g., 5-fold cross-validation)\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "\n",
    "        # Calculate the mean cross-validation score\n",
    "        mean_cv_score = np.mean(cv_scores)\n",
    "\n",
    "        # Calculate the difference between test accuracy and mean cross-validation score\n",
    "        score_difference = accuracy - mean_cv_score\n",
    "\n",
    "        # Check if the model may be overfitting based on the threshold\n",
    "        if score_difference <= 0.1:\n",
    "            # The model is not overfitting\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model_name\n",
    "                best_feature_count = count\n",
    "\n",
    "        # Append the results for the current model and feature count to the list\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Feature Count': count,\n",
    "            'Accuracy on Test Set': accuracy,\n",
    "            'Mean Cross-Validation Score': mean_cv_score,\n",
    "            'Score Difference': score_difference\n",
    "        })\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort the results DataFrame by model name\n",
    "results_df = results_df.sort_values(by=['Model', 'Feature Count'])\n",
    "\n",
    "# Print the best model and feature count\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Best Feature Count: {best_feature_count}\")\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(\"\\nResults DataFrame:\")\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
